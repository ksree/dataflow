inputs:
  sales:
    file:
      path: src/test/resources/data/sales/
      format: csv
      options:
        quoteAll: false

transformations:
  - config/sales_transformations.yaml

output:
  file:
    dir: gs://kapilsreed12-1dataflow_file_output_store
  aws:
    connectionUrl: jdbc:redshift://dataflow-redshift-cluster.ce0s1cnqwquk.us-east-2.redshift.amazonaws.com:5439/dataflow
    user: adm1n157r470r
    password: OdfdPdeanfioefn232dedw
    driver: com.amazon.redshift.jdbc42.Driver
  azure:
    connectionUrl: jdbc:sqlserver://dataflowazuresqlserver.database.windows.net:1433;database=dataflowazuresqldatabase
    user: 4dm1n157r470r
    password: 4-v3ry-53cr37-p455w0rd
    driver: com.microsoft.sqlserver.jdbc.SQLServerDriver
  gcp:
    temporaryGcsBucket: kapilsreed12-1dataflow_file_output_store

# If set to true, triggers Explain before saving
explain: true

# Set Log Level : ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN
logLevel: WARN

# Set Application Name to have app name prefix in spark instrumentation counters
appName: TransactionsApp

# Shows a Preview of the output
showPreviewLines: 5
