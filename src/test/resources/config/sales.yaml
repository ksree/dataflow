inputs:
  sales:
    file:
         # The path of the file, you can add multiple files with ,
         path: src/test/resources/data/sales/
         format: csv
         # Optional, define custom schema via a json schema file (https://json-schema.org/)
         #schemaPath: schema/schema.json
         # Optional send any spark supported option to the reader
         options:
           quoteAll: false
transformations:
  - src/test/resources/config/sales_transformations.yaml

output:
  file:
    dir: target/test-classes/output/sales/

# If set to true, triggers Explain before saving
explain: true

# Set Log Level : ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN
logLevel: WARN

# Set Application Name to have app name prefix in spark instrumentation counters
appName: TransactionsApp

# Shows a Preview of the output
showPreviewLines: 5
